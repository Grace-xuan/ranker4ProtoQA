# ranker4ProtoQA

We share the basic DeBERTaV3 ranker model in our [paper](https://aclanthology.org/2022.findings-emnlp.233/ "EMNLP 2022") for generative commonsense QA [ProtoQA](https://github.com/iesl/ProtoQA_GPT2 "GitHub").



Download the [checkpoint](https://drive.google.com/file/d/1TGegIFT5gwKcxP7hPoDLR_aQzUhShRr2/view?usp=share_link "Google Drive") trained with none negative samples in 1 epoch.

Put the ranker folder in output/ directory.



## Cite

If the code help you, please cite the following paper.

```
@inproceedings{luo-etal-2022-masked,
    title = "Masked Language Models Know Which are Popular: A Simple Ranking Strategy for Commonsense Question Answering",
    author = "Luo, Xuan  and
      Fan, Chuang  and
      Zhang, Yice  and
      Jiang, Wanguo  and
      Qin, Bing  and
      Xu, Ruifeng",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.233",
    pages = "3200--3213",
}
```
